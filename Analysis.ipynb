{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using meta-research to improve science - 2020\n",
    "## Studying methodological citations\n",
    "### Prevalence anaylysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Data\n",
    "As a first step we load the consesus data of study 2 - prevalence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib import colors\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "matplotlib.rc('font', family='sans-serif') \n",
    "matplotlib.rc('font', serif='Arial') \n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#specify file location\n",
    "data_path = Path().home() / 'MetaScience'\n",
    "data_file = 'dataset_all_fields.csv'\n",
    "\n",
    "#load csv file -- drop empty columns and rows\n",
    "#index keys = [field, journal, authors, key]\n",
    "df = pd.read_csv((data_path / data_file).open('rb'), sep = ';', encoding=r'ISO-8859-1',usecols=lambda x: 'Unnamed' not in x, index_col=[5,6,10,0], na_values=['\\xa0','\\xCA'], engine='python')\n",
    "df.dropna(how=\"all\", inplace=True)\n",
    "\n",
    "#shorten author names to last name of first author\n",
    "replace_authour_names = {l1:l2 for l1, l2 in zip(df.index.get_level_values(2),df.index.get_level_values(2).str.split().str.get(0))}\n",
    "df = df.rename(replace_authour_names)\n",
    "\n",
    "#replace all commas with decimal point\n",
    "df.replace({\"7,1\": 7.1, \"7,2\":7.2}, inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change column names to MethodCit, Cit_Reason, and Cit_SC\n",
    "new_cols = []\n",
    "skip_cols = 0\n",
    "names = ['MethCit{}', 'Cit{}_Reason', 'Cit{}_SC']\n",
    "for c in df.columns:\n",
    "    if not 'cit' in c: #skip columns that aren't citations\n",
    "        new_cols.append(c)\n",
    "        skip_cols += 1\n",
    "    else:\n",
    "        num = ''.join(filter(str.isdigit, c)) #if it is citation take its index\n",
    "        if num:\n",
    "            num = int(num) #every three entries, the column names repeat\n",
    "            name = names[(num-1)%3].format((num-1)//3 + 1)\n",
    "            new_cols.append(name)\n",
    "df.columns = new_cols\n",
    "df.iloc[:,14:24].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_float(val):\n",
    "    \"\"\"\n",
    "    Function to check whether a data entry is numerical by\n",
    "    trying to cast it to float\n",
    "    \n",
    "    Args\n",
    "        val: value to check\n",
    "    \n",
    "    Returns\n",
    "        Boolean indicating whether input is numerical\n",
    "    \"\"\"    \n",
    "    try:\n",
    "        float(val)\n",
    "    except:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "def to_numeric(x):\n",
    "    \"\"\"\n",
    "    Takes row as input and checks for non-numerical values\n",
    "    Prints all entries that are non-numerical for cleaning\n",
    "    \n",
    "    Args\n",
    "        x: dataframe row with citation classifications\n",
    "    \n",
    "    Returns\n",
    "        Index of non-numerical entries\n",
    "    \"\"\"\n",
    "    numerics = np.vectorize(is_float, otypes = [bool])(x)\n",
    "    if not all(numerics):\n",
    "        print(x[~numerics], x.shape)\n",
    "        return x.index\n",
    "\n",
    "# Applies check to all columns that specify citation reasons    \n",
    "indices = df.filter(regex='Reason').apply(to_numeric,axis=1)\n",
    "indices_additional = df.loc[:,'is_cov':'is_repo'].apply(to_numeric,axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count citations per row\n",
    "def get_last_citation(x):\n",
    "    \"\"\"\n",
    "    Calculates number of citations per entry\n",
    "    \n",
    "    Args\n",
    "        x: dataframe row \n",
    "        \n",
    "    Returns\n",
    "        The last valid citation index as count of citations per row\n",
    "    \"\"\"\n",
    "    #last citation that is not NaN\n",
    "    last = x.filter(regex='MethCit').last_valid_index()\n",
    "    if last:\n",
    "        num = ''.join(filter(str.isdigit, last)) #take digit as count\n",
    "        if num == '':\n",
    "            return 0\n",
    "        return int(num) #return cound\n",
    "    return 0\n",
    "\n",
    "# Append number of citations as column\n",
    "df['num_citations'] = df.apply(get_last_citation, axis=1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count probable and possible shortcuts\n",
    "def get_shortcuts(x):\n",
    "    \"\"\"\n",
    "    Find number of possible and probable shortcuts in each row\n",
    "    \n",
    "    Args\n",
    "        x: dataframe row\n",
    "        \n",
    "    Returns\n",
    "        Number of possible, probable, and total number of shortcuts\n",
    "    \"\"\"\n",
    "    #sum all columns that contain possible and probable respecitvely\n",
    "    possible = x.isin(['possible']).sum()\n",
    "    probable = x.isin(['probable']).sum()\n",
    "    \n",
    "    #return counts for row\n",
    "    return pd.Series({'num_possible': possible, 'num_probable': probable, 'total_shortcuts': possible+probable})\n",
    "\n",
    "# Append new variables to dataframe\n",
    "df = pd.concat([df,df.apply(get_shortcuts, axis=1)],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create quintiles of total shortcuts for sampling\n",
    "\n",
    "For study 1 - case study, articles are sorted into quintiles by total number of shortcuts. Then 10 random samples are taken per field for create candidate articles for the three different fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate quintiles\n",
    "df['quintile'] = df.groupby('field')['total_shortcuts'].transform(lambda x: pd.qcut(x,5,labels=False))\n",
    "\n",
    "# Sample 10 random articles per quintile\n",
    "samples = df.groupby(['field','quintile']).sample(10,random_state=42).loc[:,['title','total_shortcuts','quintile']]\n",
    "\n",
    "#Save as excel sheet\n",
    "samples.loc[['neuroscience','biology','psychiatry']].to_excel(data_path / 'random_samples_all.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We define colors to be used in all plots\n",
    "Neuro_7colors = np.array(['#FFFCEB',\n",
    "                            '#FFF6C2',\n",
    "                            '#FFED85',\n",
    "                            '#FFE347',\n",
    "                            '#E0BF00',\n",
    "                            '#B89C00',\n",
    "                            '#8F7900'])\n",
    "\n",
    "Psych_7colors = np.array(['#FFEEEB',\n",
    "                            '#FFCBC2',\n",
    "                            '#FF9785',\n",
    "                            '#FF6347',\n",
    "                            '#E02200',\n",
    "                            '#B81C00',\n",
    "                            '#8F1500'])\n",
    "\n",
    "Bio_7colors = np.array(['#EDF3FD',\n",
    "                            '#C8DAF9',\n",
    "                            '#90B5F3',\n",
    "                            '#598FEE',\n",
    "                            '#1558CB',\n",
    "                            '#1248A5',\n",
    "                            '#0E3881'])\n",
    "\n",
    "Neuro_4colors =  Neuro_7colors[[0, 2, 4, 6]]\n",
    "Psych_4colors =  Psych_7colors[[0, 2, 4, 6]]\n",
    "Bio_4colors =  Bio_7colors[[0, 2, 4, 6]]\n",
    "\n",
    "Neuro_3colors =  Neuro_7colors[[0, 3, 6]]\n",
    "Psych_3colors =  Psych_7colors[[0, 3, 6]]\n",
    "Bio_3colors =  Bio_7colors[[0, 3, 6]]\n",
    "\n",
    "Neuro_1color =  Neuro_7colors[3]\n",
    "Psych_1color =  Psych_7colors[3]\n",
    "Bio_1color =  Bio_7colors[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create figure of counts for Method supplements and repositories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(figsize=(9.2, 5))\n",
    "\n",
    "labels = ['Method\\nrepository','Method\\nsupplements']\n",
    "\n",
    "bar_size = 0.25\n",
    "padding = 0.25\n",
    "\n",
    "y_locs = np.arange(len(labels)) * (bar_size * 3 + padding)\n",
    "\n",
    "#calculate percentages of method supplements and repositories for biology\n",
    "supp = df.loc['biology'].is_supp.value_counts()\n",
    "supp = supp/supp.sum()*100\n",
    "repo = df.loc['biology'].is_repo.value_counts()\n",
    "repo = repo/repo.sum()*100\n",
    "\n",
    "#create bar graph\n",
    "bio = [repo.at[1],supp.at[1]]\n",
    "ax.barh(y_locs, bio , align='edge', height=bar_size, color=Bio_1color, label=f\"Biology (n={len(df.loc['biology'])})\")\n",
    "for i, v in enumerate(bio):\n",
    "    plt.text(v + 0.2, y_locs[i]+0.5*padding, \"{:2.0f}%\".format(v), fontsize=15, color=Bio_7colors[5], va=\"center\")\n",
    "\n",
    "#calculate percentages of method supplements and repositories for pschiatry\n",
    "supp = df.loc['psychiatry'].is_supp.value_counts()\n",
    "supp = supp/supp.sum()*100\n",
    "repo = df.loc['psychiatry'].is_repo.value_counts()\n",
    "repo = repo/repo.sum()*100\n",
    "\n",
    "psych = [repo.at[1],supp.at[1]]\n",
    "ax.barh(y_locs + bar_size, psych, align='edge', height=bar_size, color=Psych_1color, label=f\"Psychiatry (n={len(df.loc['psychiatry'])})\")\n",
    "for i, v in enumerate(psych):\n",
    "    plt.text(v + 0.2, y_locs[i]+bar_size+0.5*padding, \"{:2.0f}%\".format(v), fontsize=15, color=Psych_7colors[5], va=\"center\")\n",
    "\n",
    "#calculate percentages of method supplements and repositories for neuroscience \n",
    "supp = df.loc['neurobiology'].is_supp.value_counts()\n",
    "supp = supp/supp.sum()*100\n",
    "repo = df.loc['neurobiology'].is_repo.value_counts()\n",
    "repo = repo/repo.sum()*100\n",
    "\n",
    "neuro = [repo.at[1],supp.at[1]]\n",
    "ax.barh(y_locs + 2*bar_size, neuro, align='edge', height=bar_size, color=Neuro_1color, label=f\"Neuroscience (n={len(df.loc['neurobiology'])})\")\n",
    "for i, v in enumerate(neuro):\n",
    "    plt.text(v + 0.2, y_locs[i]+2*bar_size+0.5*padding, \"{:2.0f}%\".format(v), fontsize=15, color=Neuro_7colors[5], va=\"center\")\n",
    "\n",
    "ax.set(yticks=y_locs+ bar_size + 0.5*padding, yticklabels=labels, ylim=[0 - padding, len(y_locs)])\n",
    "ax.set_xlim([0,100])\n",
    "\n",
    "ax.set_title(\"Many papers report additional methods in the supplement.\\nFew papers use methods repositories.\",  fontsize=20)\n",
    "ax.set_xlabel(\"% of papers\", horizontalalignment='right',x=0.975, fontsize=15, color='darkgrey')\n",
    "# ax.tick_params(labelsize=15)\n",
    "ax.set_xticks([])\n",
    "ax.tick_params(axis='y', labelsize=15, colors='grey')\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "# plt.box(on=None)\n",
    "\n",
    "\n",
    "ax.legend()\n",
    "handles,labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles[::-1],labels[::-1], fontsize=15)\n",
    "\n",
    "#save figure\n",
    "fig.savefig('repos.svg', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['biology'].filter(regex='Reason').loc[df.loc['biology'].num_citations!=df.loc['biology'].filter(regex='Reason').astype(np.float).notna().sum(axis=1)].dropna(how='all',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['psychiatry'].filter(regex='Reason').loc[df.loc['psychiatry'].num_citations!=df.loc['psychiatry'].filter(regex='Reason').astype(np.float).notna().sum(axis=1)].dropna(how='all',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create figure of counts of categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count occurences of categories per field\n",
    "bio_counts = df.loc['biology'].filter(regex='Reason').astype(np.float).apply(pd.Series.value_counts).sum(axis=1)\n",
    "bio_total = bio_counts.sum()\n",
    "bio_perc = bio_counts/bio_total*100\n",
    "#merge categories of the same supercategory\n",
    "bio_perc = bio_perc.rename(index={13.0: 7.1, 14.0:7.2}).reset_index().replace([1.0,2.0,3.0,4.0],1.0).groupby('index').sum()\n",
    "#change order to be displayed\n",
    "bio_perc = bio_perc.reindex([1.0,7.0,7.1,7.2,8.0,9.0,6.0,10.0])\n",
    "\n",
    "#Psychology\n",
    "psych_counts = df.loc['psychiatry'].filter(regex='Reason').astype(np.float).apply(pd.Series.value_counts).sum(axis=1)\n",
    "psych_total = psych_counts.sum()\n",
    "psych_perc = psych_counts/psych_total*100\n",
    "psych_perc = psych_perc.rename(index={13.0: 7.1, 14.0:7.2}).reset_index().replace([1.0,2.0,3.0,4.0],1.0).groupby('index').sum()\n",
    "psych_perc = psych_perc.reindex([1.0,7.0,7.1,7.2,8.0,9.0,6.0,10.0])\n",
    "\n",
    "#Neuroscience\n",
    "neuro_counts = df.loc['neurobiology'].filter(regex='Reason').astype(np.float).apply(pd.Series.value_counts).sum(axis=1)\n",
    "neuro_total = neuro_counts.sum()\n",
    "neuro_perc = neuro_counts/neuro_total*100\n",
    "neuro_perc = neuro_perc.rename(index={13.0: 7.1, 14.0:7.2}).reset_index().replace([1.0,2.0,3.0,4.0],1.0).groupby('index').sum()\n",
    "neuro_perc = neuro_perc.reindex([1.0,7.0,7.1,7.2,8.0,9.0,6.0,10.0])\n",
    "\n",
    "totals = [neuro_total, bio_total, psych_total]\n",
    "percs = [neuro_perc, bio_perc, psych_perc]\n",
    "lefts = np.max(pd.concat(percs,axis=1).to_numpy(),axis=1)\n",
    "lengths = [len(df.loc['neurobiology']), len(df.loc['biology']), len(df.loc['psychiatry'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Define labels\n",
    "fields = ['Neuroscience', 'Biology', 'Psychiatry']\n",
    "categories = ['method (1-4)', 'credit (7)', 'software (7.1)', 'atlas (7.2)', 'source (8)', 'formula (9)', 'info (6)', 'other (10)']\n",
    "num_shortcats = 1\n",
    "\n",
    "#patterns for subcategories\n",
    "patterns = patterns = ['.', \"/\" , \"x\"]\n",
    "plt.rcParams.update({'hatch.color': 'red'})\n",
    "\n",
    "#figure parameters\n",
    "fontsize = 20\n",
    "cmaps = [Neuro_7colors[::-1], Bio_7colors[::-1], Psych_7colors[::-1]]\n",
    "fig, ax = plt.subplots(figsize=(15.2,5))\n",
    "for fi,field in enumerate(fields):\n",
    "    l = 0 #left border of bar\n",
    "    p = 0 #counter for bar colors (important for colors in category 7)\n",
    "    c = -1 #\n",
    "    sevens = 0\n",
    "    ec = None\n",
    "    gap = 2.5\n",
    "    va = ha = 'center'\n",
    "    \n",
    "    label = f'{field}\\n(n={totals[fi]:.0f} citations\\n from {lengths[fi]} articles)'\n",
    "    for i,v in enumerate(percs[fi].values.squeeze()):\n",
    "        if 7.0 <= percs[fi].index[i] < 8.0 :\n",
    "            ax.barh(label,v,left=l,height=.6, color=cmaps[fi][1+p],label=categories[i], edgecolor='grey', hatch=patterns[p])\n",
    "    \n",
    "            p += 1\n",
    "            l += v \n",
    "            sevens += v\n",
    "            if percs[fi].index[i]==7.2:\n",
    "                xcenter = lefts.cumsum()[0] + 2.5 + sevens/2 \n",
    "                r, g, b,_ = colors.to_rgba(cmaps[fi][1],alpha=None)\n",
    "                text_color = 'black' if fi < 1 else 'white'\n",
    "                ax.text(xcenter, fi, f'{sevens:2.0f}%', ha=ha, va=va,\n",
    "                    color=text_color,fontsize=fontsize)  \n",
    "            \n",
    "                l = lefts.cumsum()[i] + i*gap \n",
    "                gap = 9\n",
    "        else:\n",
    "            xcenter = l+v/2 if v > 10 else l+v+2.5\n",
    "            c += 1 + 1*(i==4)\n",
    "            ax.barh(label,v,left=l,height=.6, color=cmaps[fi][c],label=categories[i], edgecolor=ec)   \n",
    "           \n",
    "            r, g, b,_ = colors.to_rgba(cmaps[fi][c],alpha=None)\n",
    "            text_color = 'black' if i > 3 else 'white'\n",
    "            s = f'{v:2.0f}%' \n",
    "            if v < 1:\n",
    "                s = f'{v:2.1f}%'\n",
    "                xcenter += 4\n",
    "            ax.text(xcenter, fi, s, ha=ha, va=va,\n",
    "                color=text_color,fontsize=fontsize)   \n",
    "                   \n",
    "            l += lefts[i]+gap\n",
    "            \n",
    "        if i == num_shortcats-1:\n",
    "            ec = 'grey'\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "by_label = dict(zip(labels, handles))            \n",
    "\n",
    "plt.tight_layout()\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.set_title('Why do authors use citations in the methods section?', fontsize=20)\n",
    "ax.set_xlabel('% of papers', horizontalalignment='right',x=0.975, fontsize=15, color='darkgrey')\n",
    "ax.set_xticks([])\n",
    "ax.tick_params(axis='y', labelsize=15, colors='grey')\n",
    "\n",
    "ax.invert_yaxis()\n",
    "# fig.savefig('categories.png', bbox_inches='tight', dpi=600)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
